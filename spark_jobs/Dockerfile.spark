# Base image with Java (needed for Spark)
FROM openjdk:17-slim

# Install Python3, pip, curl, wget
RUN apt-get update && apt-get install -y python3 python3-pip curl wget && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
RUN pip3 install \
    pyspark==3.5.2 \
    kafka-python \
    pandas \
    torch \
    transformers \
    joblib \
    contractions \
    scikit-learn \
    mlflow \
    numpy

# Set working directory
WORKDIR /opt/spark-apps

# Copy Spark jobs, app, common modules, configs, and models
COPY spark_jobs/ ./spark_jobs/
COPY app-ml/ ./app-ml/
COPY common/ ./common/
COPY config/ ./config/
COPY model/ ./model/

# Copy local jars folder (optional, can be used for offline mode)
COPY jars/ ./jars/

# Fixed CMD to use --packages (like your manual working command)
CMD ["spark-submit", \
    "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.2", \
    "spark_jobs/spark_streaming_job.py"]
