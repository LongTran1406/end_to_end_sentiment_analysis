# Sentiment Analysis API
## Overview

This project provides real-time sentiment analysis of user-provided text using TF-IDF and BERT models.

It is designed for developers, companies, or anyone who wants to analyze text sentiment quickly via a REST API.

## Features

Text Prediction: Predict sentiment with both TF-IDF and BERT models

Interactive API: Send texts and retrieve predictions in real-time

Dockerized Deployment: Run locally or on cloud EC2 easily

Python Integration: Easily call the API from Python scripts

## Project Architecture

```bash
â”œâ”€â”€ .env
â”œâ”€â”€ .ipynb_checkpoints
â”‚   â””â”€â”€ Untitled-checkpoint.ipynb
â”œâ”€â”€ README_Spark_Kafka.md
â”œâ”€â”€ app-ml
â”‚   â”œâ”€â”€ entrypoint
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”œâ”€â”€ inference_api.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ src
â”‚       â”œâ”€â”€ pipelines
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ feature_engineer.py
â”‚       â”‚   â”œâ”€â”€ inferencing.py
â”‚       â”‚   â”œâ”€â”€ pipeline_runner.py
â”‚       â”‚   â”œâ”€â”€ postprocessing.py
â”‚       â”‚   â”œâ”€â”€ preprocessing.py
â”‚       â”‚   â””â”€â”€ training.py
â”‚       â””â”€â”€ prototype
â”‚           â”œâ”€â”€ .ipynb_checkpoints
â”‚           â”‚   â””â”€â”€ prototype-checkpoint.ipynb
â”‚           â””â”€â”€ prototype.ipynb
â”œâ”€â”€ common
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_manager.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ config
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ cleaned
â”‚   â”‚   â””â”€â”€ cleaned_dataset.csv
â”‚   â”œâ”€â”€ raw
â”‚   â”‚   â””â”€â”€ raw_dataset.csv
â”‚   â””â”€â”€ real_time
â”‚       â”œâ”€â”€ real_time_dataset.csv
â”‚       â””â”€â”€ test.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ generate_tree.py
â”œâ”€â”€ model
â”‚   â”œâ”€â”€ bert
â”‚   â”‚   â””â”€â”€ distilbert_model.pt
â”‚   â””â”€â”€ tfidf
â”‚       â””â”€â”€ svm_pipeline.pkl
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ result_api.py
â”œâ”€â”€ spark_jobs
â”‚   â”œâ”€â”€ Dockerfile.spark
â”‚   â””â”€â”€ spark_streaming_job.py
```
## ðŸ“Š Project Flow

![Project Flow](img/project-flow.png)

## Pipelines
### Training Pipeline

Preprocessing and Feature Engineering: Clean and encode texts for TF-IDF and BERT input.

Model Training:

Train TF-IDF + SVM classifier. (Using MLflow for keeping tracks the parameters and scoring metrices, e.g. Accuracy, F1, Recall, Precision)

Train DistilBERT for sentiment classification.

Model Saving: Store trained models for inference (svm_pipeline.pkl and distilbert_model.pt).

### Inference Pipeline

Input Handling: Receive texts via Flask API or real-time Kafka stream.

Spark Streaming: Process incoming messages in real time using PySpark, apply preprocessing, feature engineering and feed them into models.

Prediction:

Predict sentiment using TF-IDF + SVM.

Predict sentiment using BERT.

Postprocessing: Format outputs and return results via API or store in Kafka result queue.

## Quick Start
Option 1: Docker (Recommended)
### Clone repo
```bash
git clone <your-repo-url>
cd project
```

### Start services
```bash
docker-compose up --build
```

### Verify
```bash
docker-compose ps
docker-compose logs -f
```

Access API
API: http://localhost:8000

Option 2: Run Locally
### Clone repo
```bash
git clone <your-repo-url>
cd project
```

### Install dependencies
```bash
pip install -r requirements.txt
```

### Start API
```bash
python app/api/main.py
```

## Live Cloud Demo (EC2)

1. Start a session:

```bash
curl http://3.25.119.111:8000/start_session
```


Output:

```bash
{
  "client_id": "d02965ae-3928-481b-8704-493aca5df0a2"
}
```


2. Send texts for prediction:

```bash 
curl -X POST http://3.25.119.111:8000/predict \
-H "Content-Type: application/json" \
-d "{\"client_id\":\"d02965ae-3928-481b-8704-493aca5df0a2\",\"texts\":[\"I hate you\",\"Hello my name is Long, nice to meet you\",\"What is your name\",\"I love you\"]}"
```


Output:

```bash
{
  "message": "4 texts sent to Kafka for client d02965ae-3928-481b-8704-493aca5df0a2"
}
```

3. Get prediction results:
```bash
curl "http://3.25.119.111:8000/results?client_id=d02965ae-3928-481b-8704-493aca5df0a2"
```

Output:

```bash
[
  {"text":"I hate you","tfidf_prediction":0.9928,"bert_prediction":0.6267,"client_id":"d02965ae-3928-481b-8704-493aca5df0a2"},
  {"text":"Hello my name is Long, nice to meet you","tfidf_prediction":0.1324,"bert_prediction":0.4954,"client_id":"d02965ae-3928-481b-8704-493aca5df0a2"},
  {"text":"What is your name","tfidf_prediction":0.1940,"bert_prediction":0.4987,"client_id":"d02965ae-3928-481b-8704-493aca5df0a2"},
  {"text":"I love you","tfidf_prediction":0.3082,"bert_prediction":0.4843,"client_id":"d02965ae-3928-481b-8704-493aca5df0a2"}
]
```


4. Python Example Using Live API:

```bash
import requests
import time

BASE_URL = "http://3.25.119.111:8000"

# 1. Start a new session
resp = requests.get(f"{BASE_URL}/start_session")
resp.raise_for_status()
client_id = resp.json()["client_id"]
print(f"Session started: {client_id}")

# 2. Send texts for prediction
texts = [
    "I hate you",
    "Hello my name is Long, nice to meet you",
    "What is your name",
    "I love you"
]

payload = {"client_id": client_id, "texts": texts}
resp = requests.post(f"{BASE_URL}/predict", json=payload)
resp.raise_for_status()
print(resp.json())

# 3. Poll for results
results = []
while not results:
    time.sleep(1)
    resp = requests.get(f"{BASE_URL}/results", params={"client_id": client_id})
    resp.raise_for_status()
    results = resp.json()

print("Prediction results:")
for r in results:
    print(f"Text: {r['text']}")
    print(f"TF-IDF: {r['tfidf_prediction']:.3f}, BERT: {r['bert_prediction']:.3f}")
    print("---")
```

Output:
```bash
Session started: db6ee8ce-cb21-4d24-9fed-7d5e205df0f0
{'message': '4 texts sent to Kafka for client db6ee8ce-cb21-4d24-9fed-7d5e205df0f0'}
Prediction results:
Text: I hate you
TF-IDF: 0.993, BERT: 0.627
---
Text: Hello my name is Long, nice to meet you
TF-IDF: 0.132, BERT: 0.495
---
Text: What is your name
TF-IDF: 0.194, BERT: 0.499
---
Text: I love you
TF-IDF: 0.308, BERT: 0.484
---
```
